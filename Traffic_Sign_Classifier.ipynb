{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d0e20d9",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e5c345",
   "metadata": {},
   "source": [
    "Before running the code in this notebook, please ensure that you have the following packages installed. You can install them using the provided commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90484980",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install opencv-python-headless\n",
    "!pip install Pillow\n",
    "!pip install keras\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d88cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7a64da",
   "metadata": {},
   "source": [
    "Download training dataset:\n",
    "https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\n",
    "\n",
    "Zip file will contain \"Train\" folder, this should be moved to same directory as this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7945b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to check your current working directory:\n",
    "import os\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "#This is where the \"Train\" folder should be located"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aad871b",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ffe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "#Train folder should be in your working directory.\n",
    "DATADIR='Train' # Setting the directory of the dataset\n",
    "class_dict = {0: 'Speed limit (20km/h)', #links name of folder to its category\n",
    "              1: 'Speed limit (30km/h)', \n",
    "              2: 'Speed limit (50km/h)', \n",
    "              3: 'Speed limit (60km/h)', \n",
    "              4: 'Speed limit (70km/h)', \n",
    "              5: 'Speed limit (80km/h)', \n",
    "              6: 'End of speed limit (80km/h)', \n",
    "              7: 'Speed limit (100km/h)', \n",
    "              8: 'Speed limit (120km/h)', \n",
    "              9: 'No passing', \n",
    "              10: 'No passing veh over 3.5 tons', \n",
    "              11: 'Right-of-way at intersection', \n",
    "              12: 'Priority road', \n",
    "              13: 'Yield', \n",
    "              14: 'Stop', \n",
    "              15: 'No vehicles', \n",
    "              16: 'Veh > 3.5 tons prohibited', \n",
    "              17: 'No entry', \n",
    "              18: 'General caution', \n",
    "              19: 'Dangerous curve left', \n",
    "              20: 'Dangerous curve right', \n",
    "              21: 'Double curve', \n",
    "              22: 'Bumpy road', \n",
    "              23: 'Slippery road', \n",
    "              24: 'Road narrows on the right', \n",
    "              25: 'Road work', \n",
    "              26: 'Traffic signals', \n",
    "              27: 'Pedestrians', \n",
    "              28: 'Children crossing', \n",
    "              29: 'Bicycles crossing', \n",
    "              30: 'Beware of ice/snow', \n",
    "              31: 'Wild animals crossing', \n",
    "              32: 'End speed + passing limits', \n",
    "              33: 'Turn right ahead', \n",
    "              34: 'Turn left ahead', \n",
    "              35: 'Ahead only', \n",
    "              36: 'Go straight or right', \n",
    "              37: 'Go straight or left', \n",
    "              38: 'Keep right', \n",
    "              39: 'Keep left', \n",
    "              40: 'Roundabout mandatory', \n",
    "              41: 'End of no passing', \n",
    "              42: 'End no passing vehicle with a weight greater than 3.5 tons'} \n",
    "\n",
    "# Loop through each category folder in the class_dict dictionary\n",
    "for index, category in class_dict.items():\n",
    "    # Create a path to the current category folder by joining the main directory (DATADIR) with the folder index (converted to a string)\n",
    "    path = os.path.join(DATADIR, str(index))  \n",
    "    # Loop through each image file in the current category folder\n",
    "    for img in os.listdir(path):\n",
    "        # Read the image file using OpenCV, with the flag cv2.IMREAD_COLOR to ensure it's read in color format\n",
    "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)     \n",
    "        # Display the image using matplotlib\n",
    "        plt.imshow(img_array)        \n",
    "        # Add a title to the displayed image with the category name\n",
    "        plt.title(category)        \n",
    "        # Show the image plot\n",
    "        plt.show()        \n",
    "        break\n",
    "        \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca1c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_array.shape) #images not the same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3854b975",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=50\n",
    "\n",
    "new_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE)) #makes all of the images 50x50\n",
    "plt.imshow(new_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c073245a",
   "metadata": {},
   "source": [
    "# Assign Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82276bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "def create_training_data(): #Function to assign training data\n",
    "    for index, category in class_dict.items(): #Iterate through the dictionary of categories\n",
    "        path = os.path.join(DATADIR, str(index)) #Goes into each category folder\n",
    "        class_num = index #assigns a number to the current category\n",
    "        for img in os.listdir(path): # Loops through each image in current folder\n",
    "            try:\n",
    "                # Read the current image file, stores the image array in img_array\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
    "                \n",
    "                # Resizes image to 50x50\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE), cv2.IMREAD_COLOR)\n",
    "                \n",
    "                # Image array stored in list, with class_num as its label\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                  pass\n",
    "\n",
    "create_training_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e07e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_data)) #39209 total images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f4ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random #shuffles the training data\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56306362",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in training_data[:10]: #goes through 10 samples in training data\n",
    "    print(class_dict[sample[1]]) #prints the category of each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500b2c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "\n",
    "#loops through the training data, \n",
    "#assinging the features/lables to the X and Y labels\n",
    "for features,label in training_data: \n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X=np.array(X).reshape(-1,IMG_SIZE,IMG_SIZE, 3) #the 3 means 3 color chanels\n",
    "#reshaped to 50x50\n",
    "\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2315ce",
   "metadata": {},
   "source": [
    "# Export/Save Training/Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c8cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out=open('X.pickle','wb')\n",
    "pickle.dump(X,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out=open('y.pickle','wb')\n",
    "pickle.dump(y,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da571798",
   "metadata": {},
   "source": [
    "# Import Data to use in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a1357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "NAME = \"trafficsignCNN32-{}\".format(int(time.time()))\n",
    "\n",
    "tensorboard=TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "\n",
    "#Loads in features and labels\n",
    "X = pickle.load(open('X.pickle','rb'))\n",
    "y = pickle.load(open('y.pickle','rb'))\n",
    "\n",
    "#Normalizes pixel values from 0-1 (rather than 1-256)\n",
    "X = X/255.0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#First convolution layer (128 filters)\n",
    "model.add(Conv2D(128, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Second Convolution layer (128 filters)\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Output layer, set to 43, one for each category\n",
    "model.add(Dense(43))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#If the ETA is greater than 5 minutes, you may want to consider only doing 1 epoch\n",
    "model.fit(X, y, batch_size=32, epochs=5, validation_split=0.20, callbacks=[tensorboard])\n",
    "\n",
    "#Name that model will be saved as\n",
    "model.save('traffic_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380e2641",
   "metadata": {},
   "source": [
    "Accuracy should be above 80%, if it is under 10%, there is likely an issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1166c274",
   "metadata": {},
   "source": [
    "# Model Testing Prerequisites:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068aeadc",
   "metadata": {},
   "source": [
    "Using any external images of a single traffic sign type, save them to a folder in the working directory, this folder will be used as an input for the testing code below, so you may want to name it something that you will remember/understand, such as \"stopsign_test\". \n",
    "Please follow comments in code below to test your images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190a1539",
   "metadata": {},
   "source": [
    "# Tests external images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d1cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE=50 #This should match the image size used in the training set\n",
    "    img_array=cv2.imread(filepath)\n",
    "    new_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "    return new_array.reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "\n",
    "#Loads in model that was created\n",
    "model=tf.keras.models.load_model('traffic_model')\n",
    "\n",
    "#Sets folder to be tested that is in your directory\n",
    "test_folder = 'stopsign_test' #set this to the name of your testing folder\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "#Loops through all the images\n",
    "for filename in os.listdir(test_folder):\n",
    "    if filename.endswith(\".png\"):  # Selects images that are .png files\n",
    "        file_path = os.path.join(test_folder, filename)\n",
    "        prediction = model.predict([prepare(file_path)]) #makes a prediction\n",
    "        predicted_category = class_dict[prediction[0].argmax()] #uses the prediction to select a category\n",
    "        \n",
    "        print(f\"File: {filename}, Predicted Category: {predicted_category}\") #prints out each prediction\n",
    "         \n",
    "        # Set this to the category you are predicting, this name should match \n",
    "        # a class_dict name, such as \"yield\" or \"stop\"\n",
    "        if predicted_category == \"Stop\": \n",
    "            correct_predictions += 1\n",
    "        total_predictions += 1\n",
    "\n",
    "#Accuracy is printed based on number of correct predictions\n",
    "accuracy = (correct_predictions / total_predictions) * 100\n",
    "print(f\"Accuracy: {accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521feb92",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e8e7500",
   "metadata": {},
   "source": [
    "# GUI Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b23acc",
   "metadata": {},
   "source": [
    "This section runs the graphical user interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55edc200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "import numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "#load the trained model to classify sign\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "class_dict = {0: 'Speed limit (20km/h)', #links name of folder to its category\n",
    "              1: 'Speed limit (30km/h)', \n",
    "              2: 'Speed limit (50km/h)', \n",
    "              3: 'Speed limit (60km/h)', \n",
    "              4: 'Speed limit (70km/h)', \n",
    "              5: 'Speed limit (80km/h)', \n",
    "              6: 'End of speed limit (80km/h)', \n",
    "              7: 'Speed limit (100km/h)', \n",
    "              8: 'Speed limit (120km/h)', \n",
    "              9: 'No passing', \n",
    "              10: 'No passing veh over 3.5 tons', \n",
    "              11: 'Right-of-way at intersection', \n",
    "              12: 'Priority road', \n",
    "              13: 'Yield', \n",
    "              14: 'Stop', \n",
    "              15: 'No vehicles', \n",
    "              16: 'Veh > 3.5 tons prohibited', \n",
    "              17: 'No entry', \n",
    "              18: 'General caution', \n",
    "              19: 'Dangerous curve left', \n",
    "              20: 'Dangerous curve right', \n",
    "              21: 'Double curve', \n",
    "              22: 'Bumpy road', \n",
    "              23: 'Slippery road', \n",
    "              24: 'Road narrows on the right', \n",
    "              25: 'Road work', \n",
    "              26: 'Traffic signals', \n",
    "              27: 'Pedestrians', \n",
    "              28: 'Children crossing', \n",
    "              29: 'Bicycles crossing', \n",
    "              30: 'Beware of ice/snow', \n",
    "              31: 'Wild animals crossing', \n",
    "              32: 'End speed + passing limits', \n",
    "              33: 'Turn right ahead', \n",
    "              34: 'Turn left ahead', \n",
    "              35: 'Ahead only', \n",
    "              36: 'Go straight or right', \n",
    "              37: 'Go straight or left', \n",
    "              38: 'Keep right', \n",
    "              39: 'Keep left', \n",
    "              40: 'Roundabout mandatory', \n",
    "              41: 'End of no passing', \n",
    "              42: 'End no passing vehicle with a weight greater than 3.5 tons'} \n",
    "\n",
    "#Load model created earlier\n",
    "model = load_model('traffic_model')\n",
    "#initialise GUI\n",
    "top=tk.Tk()\n",
    "top.geometry('800x600')\n",
    "top.title('Traffic sign classification')\n",
    "top.configure(background='#CDCDCD')\n",
    "label=Label(top,background='#CDCDCD', font=('arial',15,'bold'))\n",
    "sign_image = Label(top)\n",
    "\n",
    "import cv2\n",
    "\n",
    "def prepare_image(file_path):\n",
    "    IMG_SIZE = 50 #This should also match the training data image size\n",
    "    img_array = cv2.imread(file_path)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "\n",
    "def classify(file_path):\n",
    "    global label_packed\n",
    "    img_array = prepare_image(file_path)\n",
    "    pred = model.predict(img_array)[0]\n",
    "    sign = class_dict[pred.argmax()]\n",
    "    print(sign)\n",
    "    label.configure(foreground='#011638', text=sign)\n",
    "\n",
    "\n",
    "def show_classify_button(file_path):\n",
    "    classify_b = Button(top, text=\"Classify Image\", command=lambda: classify(file_path), padx=10, pady=5)\n",
    "    classify_b.configure(background='#364156', foreground='white', font=('arial', 10, 'bold'))\n",
    "    classify_b.place(relx=0.79, rely=0.46)\n",
    "\n",
    "\n",
    "def upload_image():\n",
    "    try:\n",
    "        file_path = filedialog.askopenfilename()\n",
    "        uploaded = Image.open(file_path)\n",
    "        uploaded.thumbnail(((top.winfo_width() / 2.25), (top.winfo_height() / 2.25)))\n",
    "        im = ImageTk.PhotoImage(uploaded)\n",
    "        sign_image.configure(image=im)\n",
    "        sign_image.image = im\n",
    "        label.configure(text='')\n",
    "        show_classify_button(file_path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "upload = Button(top, text=\"Upload an image\", command=upload_image, padx=10, pady=5)\n",
    "upload.configure(background='#364156', foreground='white', font=('arial', 10, 'bold'))\n",
    "upload.pack(side=BOTTOM, pady=50)\n",
    "sign_image.pack(side=BOTTOM, expand=True)\n",
    "label.pack(side=BOTTOM, expand=True)\n",
    "heading = Label(top, text=\"Check traffic sign\", pady=20, font=('arial', 20, 'bold'))\n",
    "heading.configure(background='#CDCDCD', foreground='#364156')\n",
    "heading.pack()\n",
    "top.mainloop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b86f6790",
   "metadata": {},
   "source": [
    "Optional: Code optimization via tensorboard\n",
    "\n",
    "The following section of code allows you to test different combinations of dense layers, convolution layers, and number of neurons in each layer, the instructions for testing these out is commented in the code below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d48955c",
   "metadata": {},
   "source": [
    "Viewing results:\n",
    "In terminal/cmd, go to the tensorboard file location (For example: C:\\Users\\t0112np\\Anaconda3\\Scripts). This location may vary depending on where your files are stored. \n",
    "Next, type \"tensorboard --logdir=\" followed up by the logs file location created in your working directory. Here is an example:    C:\\Users\\t0112np\\Desktop\\Python_final_Project\\logs\n",
    "\n",
    "This should provide a localhost link, copy and paste this into your browseer, this will show information on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5b7e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Apr 30 12:59:19 2023\n",
    "\n",
    "@author: T0112NP\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf   # Import TensorFlow library\n",
    "from tensorflow.keras.datasets import cifar10   # Import CIFAR-10 dataset\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator   # Import image data generator from Keras\n",
    "from tensorflow.keras.models import Sequential   # Import Sequential model from Keras\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten   # Import Dense, Dropout, Activation, and Flatten layers from Keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D   # Import Conv2D and MaxPooling2D layers from Keras\n",
    "from tensorflow.keras.callbacks import TensorBoard   # Import TensorBoard callback from Keras\n",
    "\n",
    "# Define a name for the model for TensorBoard logging purposes\n",
    "NAME = \"Traffic-Signals-CNN-128x128x64\"\n",
    "\n",
    "import pickle   # Import pickle module for loading data from pickle files\n",
    "import time   # Import time module for generating a unique name for the model\n",
    "\n",
    "# Load the preprocessed images and labels from pickle files\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "# Normalize the pixel values of the images to the range [0,1]\n",
    "X = X/255.0\n",
    "\n",
    "# Define the hyperparameters to iterate over for different model configurations\n",
    "dense_layers = [1,2,3]#you can create a list to go over different values[1,3,5..]\n",
    "layer_sizes = [128]#you can create a list to go over different values[64,128,256..]\n",
    "conv_layers = [2]#you can create a list to go over different values[1,2,3,4,5..]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            \n",
    "            # Generate a unique name for the model using the current hyperparameters and the current timestamp\n",
    "            # NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            # print(NAME)\n",
    "            \n",
    "            # Define the CNN architecture\n",
    "            model = Sequential()\n",
    "            \n",
    "            model.add(Conv2D(128, (3, 3), input_shape=X.shape[1:]))   # Add the first convolutional layer with 128 filters of size 3x3 and the input shape of the images\n",
    "            model.add(Activation('relu'))   # Add the ReLU activation function\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))   # Add the max pooling layer with pool size of 2x2(window size to reduce the value of the image size)\n",
    "            \n",
    "            # Add additional convolutional layers with the specified number of filters and the ReLU activation function\n",
    "            for l in range(conv_layer-1):#conv_layer-1, where the -1 refers to the 1st hidden layer included with the image input size\n",
    "                model.add(Conv2D(layer_size, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            \n",
    "            model.add(Flatten())   # Flatten the output of the convolutional layers to a 1D vector\n",
    "            \n",
    "            # Add dense layers(pre-Output Layer) with the specified number of nodes and the ReLU activation function\n",
    "            for d in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "            \n",
    "            # Add the output layer with 43 nodes (one for each class) and the softmax activation function\n",
    "            model.add(Dense(43))\n",
    "            model.add(Activation('softmax'))\n",
    "            \n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))   # Define a TensorBoard callback with the log directory based on the model name\n",
    "            \n",
    "            model.compile(loss='sparse_categorical_crossentropy',   # Compile the model with the sparse categorical cross-entropy loss function\n",
    "                          optimizer='adam',   # Use the Adam optimizer\n",
    "                          metrics=['accuracy'])   # Evaluate the model's accuracy\n",
    "            \n",
    "            # Train the model for one epoch on a batch size\n",
    "            model.fit(X, y, batch_size=64, epochs=3, validation_split=0.3, callbacks=[tensorboard])\n",
    "model.save('Traffic-Signals-CNN-ximg_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4f3d3a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00354598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
